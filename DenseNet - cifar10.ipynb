{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Submission of DenseNet - cifar10.ipynb","provenance":[{"file_id":"1NGQjke72AS93IOpNcnE9diQEg78-sU3C","timestamp":1626431611380}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"}},"cells":[{"cell_type":"code","metadata":{"id":"wVIx_KIigxPV","executionInfo":{"status":"ok","timestamp":1626487913314,"user_tz":-330,"elapsed":2164,"user":{"displayName":"Shivam Mittal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhjHp5yKJNkwNRhkEZO4wybVuTVd3nePN7rh-Rd3g=s64","userId":"17162462432229941707"}}},"source":["# import keras\n","# from keras.datasets import cifar10\n","# from keras.models import Model, Sequential\n","# from keras.layers import Dense, Dropout, Flatten, Input, AveragePooling2D, merge, Activation\n","# from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n","# from keras.layers import Concatenate\n","# from keras.optimizers import Adam\n","from tensorflow.keras import models, layers\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import BatchNormalization, Activation, Flatten,Input\n","from tensorflow.keras.optimizers import Adam\n","from keras.regularizers import l1 ,l2\n","from keras.callbacks import ReduceLROnPlateau,ModelCheckpoint\n","from keras.optimizers import SGD"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"UNHw6luQg3gc","executionInfo":{"status":"ok","timestamp":1626487916072,"user_tz":-330,"elapsed":12,"user":{"displayName":"Shivam Mittal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhjHp5yKJNkwNRhkEZO4wybVuTVd3nePN7rh-Rd3g=s64","userId":"17162462432229941707"}}},"source":["# this part will prevent tensorflow to allocate all the avaliable GPU Memory\n","# backend\n","import tensorflow as tf"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"dsO_yGxcg5D8","executionInfo":{"status":"ok","timestamp":1626487920943,"user_tz":-330,"elapsed":10,"user":{"displayName":"Shivam Mittal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhjHp5yKJNkwNRhkEZO4wybVuTVd3nePN7rh-Rd3g=s64","userId":"17162462432229941707"}}},"source":["# Hyperparameters\n","batch_size = 128\n","num_classes = 10\n","epochs = 10\n","l = 40\n","num_filter = 12\n","compression = 0.5\n","dropout_rate = 0.2"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"mB7o3zu1g6eT","executionInfo":{"status":"ok","timestamp":1626487969073,"user_tz":-330,"elapsed":1225,"user":{"displayName":"Shivam Mittal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhjHp5yKJNkwNRhkEZO4wybVuTVd3nePN7rh-Rd3g=s64","userId":"17162462432229941707"}}},"source":["# Load CIFAR10 Data\n","(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n","img_height, img_width, channel = x_train.shape[1],x_train.shape[2],x_train.shape[3]\n","\n","# convert to one hot encoing \n","y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n","y_test = tf.keras.utils.to_categorical(y_test, num_classes) "],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"3lAk_Mw_5-rn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626487978964,"user_tz":-330,"elapsed":395,"user":{"displayName":"Shivam Mittal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhjHp5yKJNkwNRhkEZO4wybVuTVd3nePN7rh-Rd3g=s64","userId":"17162462432229941707"}},"outputId":"0e5c5e37-0871-4fdc-a68d-73669952cb47"},"source":["x_train.shape"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(50000, 32, 32, 3)"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"DVkpgHsc5-rp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626487985721,"user_tz":-330,"elapsed":601,"user":{"displayName":"Shivam Mittal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhjHp5yKJNkwNRhkEZO4wybVuTVd3nePN7rh-Rd3g=s64","userId":"17162462432229941707"}},"outputId":"bf5af592-0ac8-44ef-c901-219658898ea9"},"source":["x_test.shape"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(10000, 32, 32, 3)"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"ee-sge5Kg7vr"},"source":["# Dense Block\n","def denseblock(input, num_filter = 16, dropout_rate = 0.2):\n","    global compression\n","    temp = input\n","    for _ in range(l): \n","        BatchNorm = layers.BatchNormalization(beta_regularizer=l2(wd),gamma_regularizer=l2(wd))(temp)\n","        relu = layers.Activation('relu')(BatchNorm)\n","        Conv2D_3_3 = layers.Conv2D(int(num_filter*compression), (3,3), use_bias=False ,padding='same',kernel_initializer=\"he_uniform\",kernel_regularizer=l2(wd))(relu)\n","        if dropout_rate>0:\n","            Conv2D_3_3 = layers.Dropout(dropout_rate)(Conv2D_3_3)\n","        concat = layers.Concatenate(axis=-1)([temp,Conv2D_3_3])\n","        \n","        temp = concat\n","        \n","    return temp\n","\n","## transition Blosck\n","\n","\n","def transition(input, num_filter = 16, dropout_rate = 0.2):\n","    global compression\n","    BatchNorm = layers.BatchNormalization(beta_regularizer=l2(wd),gamma_regularizer=l2(wd))(input)\n","    relu = layers.Activation('relu')(BatchNorm)\n","    Conv2D_BottleNeck = layers.Conv2D(int(num_filter*compression), (1,1), use_bias=False ,padding='same',kernel_initializer=\"he_uniform\",kernel_regularizer=l2(wd))(relu)\n","    if dropout_rate>0:\n","         Conv2D_BottleNeck = layers.Dropout(dropout_rate)(Conv2D_BottleNeck)\n","    avg = layers.AveragePooling2D(pool_size=(2,2))(Conv2D_BottleNeck)\n","    return avg\n","\n","#output layer\n","def output_layer(input):\n","    global compression\n","    BatchNorm = layers.BatchNormalization(beta_regularizer=l2(wd),gamma_regularizer=l2(wd))(input)\n","    relu = layers.Activation('relu')(BatchNorm)\n","    AvgPooling = layers.AveragePooling2D(pool_size=(2,2))(relu)\n","    flat = layers.Flatten()(AvgPooling)\n","    output = layers.Dense(num_classes, activation='softmax')(flat)\n","    return output"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8KZiYSSFPcMT"},"source":["# Dense Block\n","def add_denseblock(input, l, num_filter = 16, dropout_rate = 0.2):\n","  temp = input\n","  for _ in range(int(l)):\n","    BatchNorm = BatchNormalization(beta_regularizer=l2(wd),gamma_regularizer=l2(wd))(temp)\n","    relu = Activation('relu')(BatchNorm)\n","    Conv2D_1_1 = Conv2D(int(num_filter*4),(1,1), use_bias= False, padding='same',kernel_initializer=\"he_uniform\",kernel_regularizer=l2(wd))(relu)\n","    if dropout_rate>0:\n","      Conv2D_1_1 = Dropout(dropout_rate)(Conv2D_1_1)\n","    BatchNorm = BatchNormalization(beta_regularizer=l2(wd),gamma_regularizer=l2(wd))(Conv2D_1_1)\n","    relu = Activation('relu')(BatchNorm)\n","    Conv2D_3_3 = Conv2D(int(num_filter), (3,3), use_bias=False ,padding='same',kernel_initializer=\"he_uniform\",kernel_regularizer=l2(wd))(relu)\n","    if dropout_rate>0:\n","      Conv2D_3_3 = Dropout(dropout_rate)(Conv2D_3_3)\n","    concat = Concatenate(axis=-1)([temp,Conv2D_3_3])\n","    temp = concat\n","        \n","  return temp\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"T61WA1npPked"},"source":["def add_transition(input,  dropout_rate = 0.2,num_filter = 16,):\n","    BatchNorm = BatchNormalization(beta_regularizer=l2(wd),gamma_regularizer=l2(wd))(input)\n","    relu = Activation('relu')(BatchNorm)\n","    Conv2D_BottleNeck = Conv2D(int(num_filter), (1,1), use_bias=False ,padding='same',kernel_initializer=\"he_uniform\",kernel_regularizer=l2(wd))(relu)\n","    if dropout_rate>0:\n","      Conv2D_BottleNeck = Dropout(dropout_rate)(Conv2D_BottleNeck)\n","    avg = AveragePooling2D()(Conv2D_BottleNeck)\n","    \n","    return avg"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"W3lB__j9PkgC"},"source":["def output_layer(input):\n","    BatchNorm = BatchNormalization(beta_regularizer=l2(wd),gamma_regularizer=l2(wd))(input)\n","    relu = Activation('relu')(BatchNorm)\n","    GP = GlobalAveragePooling2D()(relu)\n","    output = Dense(num_classes, activation='softmax',kernel_regularizer=l2(wd))(GP)\n","    \n","    return output"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ECKPnq6YPq8A"},"source":["wd=1e-4\n","global wd\n","growth_rate=13\n","num_filter=4*growth_rate\n","reduction=0.5\n","depth=100\n","reduction_1=0.5\n","reduction_2=0.5\n","no_layer=(depth-4)//6\n","dropout_rate=0.2\n","\n","\n","input = Input(shape=(img_height, img_width, channel,))\n","First_Conv2D = Conv2D(num_filter, (3,3), use_bias=False ,padding='same', kernel_initializer='he_uniform', bias_initializer='zeros',\n","                      kernel_regularizer=l2(wd))(input)\n","\n","First_Block = add_denseblock(First_Conv2D,no_layer ,growth_rate ,dropout_rate)\n","num_filter=math.floor((num_filter+no_layer*growth_rate))*reduction_1\n","First_Transition = add_transition(First_Block, dropout_rate, num_filter=num_filter)\n","\n","Second_Block = add_denseblock(First_Transition,no_layer,growth_rate,dropout_rate)\n","num_filter=math.floor((num_filter+no_layer*growth_rate))*reduction_2\n","Second_Transition = add_transition(Second_Block, dropout_rate, num_filter=num_filter)\n","\n","Third_Block = add_denseblock(Second_Transition,no_layer,growth_rate,dropout_rate )\n","#Third_Transition = add_transition(Third_Block, dropout_rate, num_filter=171)\n","\n","#Last_Block = add_denseblock(Third_Transition, dropout_rate,l, num_filter)\n","output = output_layer(Third_Block)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"anPCpQWhhGb7"},"source":["wd=1e-4\n","global wd\n","num_filter = 52\n","num_layer=16\n","dropout_rate = 0.2\n","l = 12\n","input =Input(shape=(img_height, img_width, channel,))\n","First_Conv2D = layers.Conv2D(num_filter, (3,3), use_bias=False ,padding='same', kernel_initializer='he_uniform', bias_initializer='zeros',\n","                      kernel_regularizer=l2(wd))(input)\n","\n","First_Block = denseblock(First_Conv2D, num_layer, dropout_rate)\n","First_Transition = transition(First_Block, num_layer, dropout_rate)\n","\n","Second_Block = denseblock(First_Transition, num_layer, dropout_rate)\n","Second_Transition = transition(Second_Block, num_layer, dropout_rate)\n","\n","Third_Block = denseblock(Second_Transition, num_layer, dropout_rate)\n","Third_Transition = transition(Third_Block, num_layer, dropout_rate)\n","\n","Last_Block = denseblock(Third_Transition,  num_layer, dropout_rate)\n","output = output_layer(Last_Block)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"c5Wksy8z5-rw"},"source":["#https://arxiv.org/pdf/1608.06993.pdf\n","from IPython.display import IFrame, YouTubeVideo\n","YouTubeVideo(id='-W6y8xnd--U', width=600)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1kFh7pdxhNtT","scrolled":true,"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626439907298,"user_tz":-330,"elapsed":768,"user":{"displayName":"Shivam Mittal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhjHp5yKJNkwNRhkEZO4wybVuTVd3nePN7rh-Rd3g=s64","userId":"17162462432229941707"}},"outputId":"db1bf676-015c-4fa9-ef99-6d3028a60516"},"source":["model = Model(inputs=[input], outputs=[output])\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_3 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n","__________________________________________________________________________________________________\n","conv2d (Conv2D)                 (None, 32, 32, 52)   1404        input_3[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization (BatchNorma (None, 32, 32, 52)   208         conv2d[0][0]                     \n","__________________________________________________________________________________________________\n","activation (Activation)         (None, 32, 32, 52)   0           batch_normalization[0][0]        \n","__________________________________________________________________________________________________\n","conv2d_1 (Conv2D)               (None, 32, 32, 8)    3744        activation[0][0]                 \n","__________________________________________________________________________________________________\n","dropout (Dropout)               (None, 32, 32, 8)    0           conv2d_1[0][0]                   \n","__________________________________________________________________________________________________\n","concatenate (Concatenate)       (None, 32, 32, 60)   0           conv2d[0][0]                     \n","                                                                 dropout[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization_1 (BatchNor (None, 32, 32, 60)   240         concatenate[0][0]                \n","__________________________________________________________________________________________________\n","activation_1 (Activation)       (None, 32, 32, 60)   0           batch_normalization_1[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_2 (Conv2D)               (None, 32, 32, 8)    4320        activation_1[0][0]               \n","__________________________________________________________________________________________________\n","dropout_1 (Dropout)             (None, 32, 32, 8)    0           conv2d_2[0][0]                   \n","__________________________________________________________________________________________________\n","concatenate_1 (Concatenate)     (None, 32, 32, 68)   0           concatenate[0][0]                \n","                                                                 dropout_1[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_2 (BatchNor (None, 32, 32, 68)   272         concatenate_1[0][0]              \n","__________________________________________________________________________________________________\n","activation_2 (Activation)       (None, 32, 32, 68)   0           batch_normalization_2[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_3 (Conv2D)               (None, 32, 32, 8)    4896        activation_2[0][0]               \n","__________________________________________________________________________________________________\n","dropout_2 (Dropout)             (None, 32, 32, 8)    0           conv2d_3[0][0]                   \n","__________________________________________________________________________________________________\n","concatenate_2 (Concatenate)     (None, 32, 32, 76)   0           concatenate_1[0][0]              \n","                                                                 dropout_2[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_3 (BatchNor (None, 32, 32, 76)   304         concatenate_2[0][0]              \n","__________________________________________________________________________________________________\n","activation_3 (Activation)       (None, 32, 32, 76)   0           batch_normalization_3[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_4 (Conv2D)               (None, 32, 32, 8)    5472        activation_3[0][0]               \n","__________________________________________________________________________________________________\n","dropout_3 (Dropout)             (None, 32, 32, 8)    0           conv2d_4[0][0]                   \n","__________________________________________________________________________________________________\n","concatenate_3 (Concatenate)     (None, 32, 32, 84)   0           concatenate_2[0][0]              \n","                                                                 dropout_3[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_4 (BatchNor (None, 32, 32, 84)   336         concatenate_3[0][0]              \n","__________________________________________________________________________________________________\n","activation_4 (Activation)       (None, 32, 32, 84)   0           batch_normalization_4[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_5 (Conv2D)               (None, 32, 32, 8)    6048        activation_4[0][0]               \n","__________________________________________________________________________________________________\n","dropout_4 (Dropout)             (None, 32, 32, 8)    0           conv2d_5[0][0]                   \n","__________________________________________________________________________________________________\n","concatenate_4 (Concatenate)     (None, 32, 32, 92)   0           concatenate_3[0][0]              \n","                                                                 dropout_4[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_5 (BatchNor (None, 32, 32, 92)   368         concatenate_4[0][0]              \n","__________________________________________________________________________________________________\n","activation_5 (Activation)       (None, 32, 32, 92)   0           batch_normalization_5[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_6 (Conv2D)               (None, 32, 32, 8)    6624        activation_5[0][0]               \n","__________________________________________________________________________________________________\n","dropout_5 (Dropout)             (None, 32, 32, 8)    0           conv2d_6[0][0]                   \n","__________________________________________________________________________________________________\n","concatenate_5 (Concatenate)     (None, 32, 32, 100)  0           concatenate_4[0][0]              \n","                                                                 dropout_5[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_6 (BatchNor (None, 32, 32, 100)  400         concatenate_5[0][0]              \n","__________________________________________________________________________________________________\n","activation_6 (Activation)       (None, 32, 32, 100)  0           batch_normalization_6[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_7 (Conv2D)               (None, 32, 32, 8)    7200        activation_6[0][0]               \n","__________________________________________________________________________________________________\n","dropout_6 (Dropout)             (None, 32, 32, 8)    0           conv2d_7[0][0]                   \n","__________________________________________________________________________________________________\n","concatenate_6 (Concatenate)     (None, 32, 32, 108)  0           concatenate_5[0][0]              \n","                                                                 dropout_6[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_7 (BatchNor (None, 32, 32, 108)  432         concatenate_6[0][0]              \n","__________________________________________________________________________________________________\n","activation_7 (Activation)       (None, 32, 32, 108)  0           batch_normalization_7[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_8 (Conv2D)               (None, 32, 32, 8)    7776        activation_7[0][0]               \n","__________________________________________________________________________________________________\n","dropout_7 (Dropout)             (None, 32, 32, 8)    0           conv2d_8[0][0]                   \n","__________________________________________________________________________________________________\n","concatenate_7 (Concatenate)     (None, 32, 32, 116)  0           concatenate_6[0][0]              \n","                                                                 dropout_7[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_8 (BatchNor (None, 32, 32, 116)  464         concatenate_7[0][0]              \n","__________________________________________________________________________________________________\n","activation_8 (Activation)       (None, 32, 32, 116)  0           batch_normalization_8[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_9 (Conv2D)               (None, 32, 32, 8)    8352        activation_8[0][0]               \n","__________________________________________________________________________________________________\n","dropout_8 (Dropout)             (None, 32, 32, 8)    0           conv2d_9[0][0]                   \n","__________________________________________________________________________________________________\n","concatenate_8 (Concatenate)     (None, 32, 32, 124)  0           concatenate_7[0][0]              \n","                                                                 dropout_8[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_9 (BatchNor (None, 32, 32, 124)  496         concatenate_8[0][0]              \n","__________________________________________________________________________________________________\n","activation_9 (Activation)       (None, 32, 32, 124)  0           batch_normalization_9[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_10 (Conv2D)              (None, 32, 32, 8)    8928        activation_9[0][0]               \n","__________________________________________________________________________________________________\n","dropout_9 (Dropout)             (None, 32, 32, 8)    0           conv2d_10[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_9 (Concatenate)     (None, 32, 32, 132)  0           concatenate_8[0][0]              \n","                                                                 dropout_9[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_10 (BatchNo (None, 32, 32, 132)  528         concatenate_9[0][0]              \n","__________________________________________________________________________________________________\n","activation_10 (Activation)      (None, 32, 32, 132)  0           batch_normalization_10[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_11 (Conv2D)              (None, 32, 32, 8)    9504        activation_10[0][0]              \n","__________________________________________________________________________________________________\n","dropout_10 (Dropout)            (None, 32, 32, 8)    0           conv2d_11[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_10 (Concatenate)    (None, 32, 32, 140)  0           concatenate_9[0][0]              \n","                                                                 dropout_10[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_11 (BatchNo (None, 32, 32, 140)  560         concatenate_10[0][0]             \n","__________________________________________________________________________________________________\n","activation_11 (Activation)      (None, 32, 32, 140)  0           batch_normalization_11[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_12 (Conv2D)              (None, 32, 32, 8)    10080       activation_11[0][0]              \n","__________________________________________________________________________________________________\n","dropout_11 (Dropout)            (None, 32, 32, 8)    0           conv2d_12[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_11 (Concatenate)    (None, 32, 32, 148)  0           concatenate_10[0][0]             \n","                                                                 dropout_11[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_12 (BatchNo (None, 32, 32, 148)  592         concatenate_11[0][0]             \n","__________________________________________________________________________________________________\n","activation_12 (Activation)      (None, 32, 32, 148)  0           batch_normalization_12[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_13 (Conv2D)              (None, 32, 32, 8)    1184        activation_12[0][0]              \n","__________________________________________________________________________________________________\n","dropout_12 (Dropout)            (None, 32, 32, 8)    0           conv2d_13[0][0]                  \n","__________________________________________________________________________________________________\n","average_pooling2d (AveragePooli (None, 16, 16, 8)    0           dropout_12[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_13 (BatchNo (None, 16, 16, 8)    32          average_pooling2d[0][0]          \n","__________________________________________________________________________________________________\n","activation_13 (Activation)      (None, 16, 16, 8)    0           batch_normalization_13[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_14 (Conv2D)              (None, 16, 16, 8)    576         activation_13[0][0]              \n","__________________________________________________________________________________________________\n","dropout_13 (Dropout)            (None, 16, 16, 8)    0           conv2d_14[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_12 (Concatenate)    (None, 16, 16, 16)   0           average_pooling2d[0][0]          \n","                                                                 dropout_13[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_14 (BatchNo (None, 16, 16, 16)   64          concatenate_12[0][0]             \n","__________________________________________________________________________________________________\n","activation_14 (Activation)      (None, 16, 16, 16)   0           batch_normalization_14[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_15 (Conv2D)              (None, 16, 16, 8)    1152        activation_14[0][0]              \n","__________________________________________________________________________________________________\n","dropout_14 (Dropout)            (None, 16, 16, 8)    0           conv2d_15[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_13 (Concatenate)    (None, 16, 16, 24)   0           concatenate_12[0][0]             \n","                                                                 dropout_14[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_15 (BatchNo (None, 16, 16, 24)   96          concatenate_13[0][0]             \n","__________________________________________________________________________________________________\n","activation_15 (Activation)      (None, 16, 16, 24)   0           batch_normalization_15[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_16 (Conv2D)              (None, 16, 16, 8)    1728        activation_15[0][0]              \n","__________________________________________________________________________________________________\n","dropout_15 (Dropout)            (None, 16, 16, 8)    0           conv2d_16[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_14 (Concatenate)    (None, 16, 16, 32)   0           concatenate_13[0][0]             \n","                                                                 dropout_15[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_16 (BatchNo (None, 16, 16, 32)   128         concatenate_14[0][0]             \n","__________________________________________________________________________________________________\n","activation_16 (Activation)      (None, 16, 16, 32)   0           batch_normalization_16[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_17 (Conv2D)              (None, 16, 16, 8)    2304        activation_16[0][0]              \n","__________________________________________________________________________________________________\n","dropout_16 (Dropout)            (None, 16, 16, 8)    0           conv2d_17[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_15 (Concatenate)    (None, 16, 16, 40)   0           concatenate_14[0][0]             \n","                                                                 dropout_16[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_17 (BatchNo (None, 16, 16, 40)   160         concatenate_15[0][0]             \n","__________________________________________________________________________________________________\n","activation_17 (Activation)      (None, 16, 16, 40)   0           batch_normalization_17[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_18 (Conv2D)              (None, 16, 16, 8)    2880        activation_17[0][0]              \n","__________________________________________________________________________________________________\n","dropout_17 (Dropout)            (None, 16, 16, 8)    0           conv2d_18[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_16 (Concatenate)    (None, 16, 16, 48)   0           concatenate_15[0][0]             \n","                                                                 dropout_17[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_18 (BatchNo (None, 16, 16, 48)   192         concatenate_16[0][0]             \n","__________________________________________________________________________________________________\n","activation_18 (Activation)      (None, 16, 16, 48)   0           batch_normalization_18[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_19 (Conv2D)              (None, 16, 16, 8)    3456        activation_18[0][0]              \n","__________________________________________________________________________________________________\n","dropout_18 (Dropout)            (None, 16, 16, 8)    0           conv2d_19[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_17 (Concatenate)    (None, 16, 16, 56)   0           concatenate_16[0][0]             \n","                                                                 dropout_18[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_19 (BatchNo (None, 16, 16, 56)   224         concatenate_17[0][0]             \n","__________________________________________________________________________________________________\n","activation_19 (Activation)      (None, 16, 16, 56)   0           batch_normalization_19[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_20 (Conv2D)              (None, 16, 16, 8)    4032        activation_19[0][0]              \n","__________________________________________________________________________________________________\n","dropout_19 (Dropout)            (None, 16, 16, 8)    0           conv2d_20[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_18 (Concatenate)    (None, 16, 16, 64)   0           concatenate_17[0][0]             \n","                                                                 dropout_19[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_20 (BatchNo (None, 16, 16, 64)   256         concatenate_18[0][0]             \n","__________________________________________________________________________________________________\n","activation_20 (Activation)      (None, 16, 16, 64)   0           batch_normalization_20[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_21 (Conv2D)              (None, 16, 16, 8)    4608        activation_20[0][0]              \n","__________________________________________________________________________________________________\n","dropout_20 (Dropout)            (None, 16, 16, 8)    0           conv2d_21[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_19 (Concatenate)    (None, 16, 16, 72)   0           concatenate_18[0][0]             \n","                                                                 dropout_20[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_21 (BatchNo (None, 16, 16, 72)   288         concatenate_19[0][0]             \n","__________________________________________________________________________________________________\n","activation_21 (Activation)      (None, 16, 16, 72)   0           batch_normalization_21[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_22 (Conv2D)              (None, 16, 16, 8)    5184        activation_21[0][0]              \n","__________________________________________________________________________________________________\n","dropout_21 (Dropout)            (None, 16, 16, 8)    0           conv2d_22[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_20 (Concatenate)    (None, 16, 16, 80)   0           concatenate_19[0][0]             \n","                                                                 dropout_21[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_22 (BatchNo (None, 16, 16, 80)   320         concatenate_20[0][0]             \n","__________________________________________________________________________________________________\n","activation_22 (Activation)      (None, 16, 16, 80)   0           batch_normalization_22[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_23 (Conv2D)              (None, 16, 16, 8)    5760        activation_22[0][0]              \n","__________________________________________________________________________________________________\n","dropout_22 (Dropout)            (None, 16, 16, 8)    0           conv2d_23[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_21 (Concatenate)    (None, 16, 16, 88)   0           concatenate_20[0][0]             \n","                                                                 dropout_22[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_23 (BatchNo (None, 16, 16, 88)   352         concatenate_21[0][0]             \n","__________________________________________________________________________________________________\n","activation_23 (Activation)      (None, 16, 16, 88)   0           batch_normalization_23[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_24 (Conv2D)              (None, 16, 16, 8)    6336        activation_23[0][0]              \n","__________________________________________________________________________________________________\n","dropout_23 (Dropout)            (None, 16, 16, 8)    0           conv2d_24[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_22 (Concatenate)    (None, 16, 16, 96)   0           concatenate_21[0][0]             \n","                                                                 dropout_23[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_24 (BatchNo (None, 16, 16, 96)   384         concatenate_22[0][0]             \n","__________________________________________________________________________________________________\n","activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_24[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_25 (Conv2D)              (None, 16, 16, 8)    6912        activation_24[0][0]              \n","__________________________________________________________________________________________________\n","dropout_24 (Dropout)            (None, 16, 16, 8)    0           conv2d_25[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_23 (Concatenate)    (None, 16, 16, 104)  0           concatenate_22[0][0]             \n","                                                                 dropout_24[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_25 (BatchNo (None, 16, 16, 104)  416         concatenate_23[0][0]             \n","__________________________________________________________________________________________________\n","activation_25 (Activation)      (None, 16, 16, 104)  0           batch_normalization_25[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_26 (Conv2D)              (None, 16, 16, 8)    832         activation_25[0][0]              \n","__________________________________________________________________________________________________\n","dropout_25 (Dropout)            (None, 16, 16, 8)    0           conv2d_26[0][0]                  \n","__________________________________________________________________________________________________\n","average_pooling2d_1 (AveragePoo (None, 8, 8, 8)      0           dropout_25[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_26 (BatchNo (None, 8, 8, 8)      32          average_pooling2d_1[0][0]        \n","__________________________________________________________________________________________________\n","activation_26 (Activation)      (None, 8, 8, 8)      0           batch_normalization_26[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_27 (Conv2D)              (None, 8, 8, 8)      576         activation_26[0][0]              \n","__________________________________________________________________________________________________\n","dropout_26 (Dropout)            (None, 8, 8, 8)      0           conv2d_27[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_24 (Concatenate)    (None, 8, 8, 16)     0           average_pooling2d_1[0][0]        \n","                                                                 dropout_26[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_27 (BatchNo (None, 8, 8, 16)     64          concatenate_24[0][0]             \n","__________________________________________________________________________________________________\n","activation_27 (Activation)      (None, 8, 8, 16)     0           batch_normalization_27[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_28 (Conv2D)              (None, 8, 8, 8)      1152        activation_27[0][0]              \n","__________________________________________________________________________________________________\n","dropout_27 (Dropout)            (None, 8, 8, 8)      0           conv2d_28[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_25 (Concatenate)    (None, 8, 8, 24)     0           concatenate_24[0][0]             \n","                                                                 dropout_27[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_28 (BatchNo (None, 8, 8, 24)     96          concatenate_25[0][0]             \n","__________________________________________________________________________________________________\n","activation_28 (Activation)      (None, 8, 8, 24)     0           batch_normalization_28[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_29 (Conv2D)              (None, 8, 8, 8)      1728        activation_28[0][0]              \n","__________________________________________________________________________________________________\n","dropout_28 (Dropout)            (None, 8, 8, 8)      0           conv2d_29[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_26 (Concatenate)    (None, 8, 8, 32)     0           concatenate_25[0][0]             \n","                                                                 dropout_28[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_29 (BatchNo (None, 8, 8, 32)     128         concatenate_26[0][0]             \n","__________________________________________________________________________________________________\n","activation_29 (Activation)      (None, 8, 8, 32)     0           batch_normalization_29[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_30 (Conv2D)              (None, 8, 8, 8)      2304        activation_29[0][0]              \n","__________________________________________________________________________________________________\n","dropout_29 (Dropout)            (None, 8, 8, 8)      0           conv2d_30[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_27 (Concatenate)    (None, 8, 8, 40)     0           concatenate_26[0][0]             \n","                                                                 dropout_29[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_30 (BatchNo (None, 8, 8, 40)     160         concatenate_27[0][0]             \n","__________________________________________________________________________________________________\n","activation_30 (Activation)      (None, 8, 8, 40)     0           batch_normalization_30[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_31 (Conv2D)              (None, 8, 8, 8)      2880        activation_30[0][0]              \n","__________________________________________________________________________________________________\n","dropout_30 (Dropout)            (None, 8, 8, 8)      0           conv2d_31[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_28 (Concatenate)    (None, 8, 8, 48)     0           concatenate_27[0][0]             \n","                                                                 dropout_30[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_31 (BatchNo (None, 8, 8, 48)     192         concatenate_28[0][0]             \n","__________________________________________________________________________________________________\n","activation_31 (Activation)      (None, 8, 8, 48)     0           batch_normalization_31[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_32 (Conv2D)              (None, 8, 8, 8)      3456        activation_31[0][0]              \n","__________________________________________________________________________________________________\n","dropout_31 (Dropout)            (None, 8, 8, 8)      0           conv2d_32[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_29 (Concatenate)    (None, 8, 8, 56)     0           concatenate_28[0][0]             \n","                                                                 dropout_31[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_32 (BatchNo (None, 8, 8, 56)     224         concatenate_29[0][0]             \n","__________________________________________________________________________________________________\n","activation_32 (Activation)      (None, 8, 8, 56)     0           batch_normalization_32[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_33 (Conv2D)              (None, 8, 8, 8)      4032        activation_32[0][0]              \n","__________________________________________________________________________________________________\n","dropout_32 (Dropout)            (None, 8, 8, 8)      0           conv2d_33[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_30 (Concatenate)    (None, 8, 8, 64)     0           concatenate_29[0][0]             \n","                                                                 dropout_32[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_33 (BatchNo (None, 8, 8, 64)     256         concatenate_30[0][0]             \n","__________________________________________________________________________________________________\n","activation_33 (Activation)      (None, 8, 8, 64)     0           batch_normalization_33[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_34 (Conv2D)              (None, 8, 8, 8)      4608        activation_33[0][0]              \n","__________________________________________________________________________________________________\n","dropout_33 (Dropout)            (None, 8, 8, 8)      0           conv2d_34[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_31 (Concatenate)    (None, 8, 8, 72)     0           concatenate_30[0][0]             \n","                                                                 dropout_33[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_34 (BatchNo (None, 8, 8, 72)     288         concatenate_31[0][0]             \n","__________________________________________________________________________________________________\n","activation_34 (Activation)      (None, 8, 8, 72)     0           batch_normalization_34[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_35 (Conv2D)              (None, 8, 8, 8)      5184        activation_34[0][0]              \n","__________________________________________________________________________________________________\n","dropout_34 (Dropout)            (None, 8, 8, 8)      0           conv2d_35[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_32 (Concatenate)    (None, 8, 8, 80)     0           concatenate_31[0][0]             \n","                                                                 dropout_34[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_35 (BatchNo (None, 8, 8, 80)     320         concatenate_32[0][0]             \n","__________________________________________________________________________________________________\n","activation_35 (Activation)      (None, 8, 8, 80)     0           batch_normalization_35[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_36 (Conv2D)              (None, 8, 8, 8)      5760        activation_35[0][0]              \n","__________________________________________________________________________________________________\n","dropout_35 (Dropout)            (None, 8, 8, 8)      0           conv2d_36[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_33 (Concatenate)    (None, 8, 8, 88)     0           concatenate_32[0][0]             \n","                                                                 dropout_35[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_36 (BatchNo (None, 8, 8, 88)     352         concatenate_33[0][0]             \n","__________________________________________________________________________________________________\n","activation_36 (Activation)      (None, 8, 8, 88)     0           batch_normalization_36[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_37 (Conv2D)              (None, 8, 8, 8)      6336        activation_36[0][0]              \n","__________________________________________________________________________________________________\n","dropout_36 (Dropout)            (None, 8, 8, 8)      0           conv2d_37[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_34 (Concatenate)    (None, 8, 8, 96)     0           concatenate_33[0][0]             \n","                                                                 dropout_36[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_37 (BatchNo (None, 8, 8, 96)     384         concatenate_34[0][0]             \n","__________________________________________________________________________________________________\n","activation_37 (Activation)      (None, 8, 8, 96)     0           batch_normalization_37[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_38 (Conv2D)              (None, 8, 8, 8)      6912        activation_37[0][0]              \n","__________________________________________________________________________________________________\n","dropout_37 (Dropout)            (None, 8, 8, 8)      0           conv2d_38[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_35 (Concatenate)    (None, 8, 8, 104)    0           concatenate_34[0][0]             \n","                                                                 dropout_37[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_38 (BatchNo (None, 8, 8, 104)    416         concatenate_35[0][0]             \n","__________________________________________________________________________________________________\n","activation_38 (Activation)      (None, 8, 8, 104)    0           batch_normalization_38[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_39 (Conv2D)              (None, 8, 8, 8)      832         activation_38[0][0]              \n","__________________________________________________________________________________________________\n","dropout_38 (Dropout)            (None, 8, 8, 8)      0           conv2d_39[0][0]                  \n","__________________________________________________________________________________________________\n","average_pooling2d_2 (AveragePoo (None, 4, 4, 8)      0           dropout_38[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_39 (BatchNo (None, 4, 4, 8)      32          average_pooling2d_2[0][0]        \n","__________________________________________________________________________________________________\n","activation_39 (Activation)      (None, 4, 4, 8)      0           batch_normalization_39[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_40 (Conv2D)              (None, 4, 4, 8)      576         activation_39[0][0]              \n","__________________________________________________________________________________________________\n","dropout_39 (Dropout)            (None, 4, 4, 8)      0           conv2d_40[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_36 (Concatenate)    (None, 4, 4, 16)     0           average_pooling2d_2[0][0]        \n","                                                                 dropout_39[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_40 (BatchNo (None, 4, 4, 16)     64          concatenate_36[0][0]             \n","__________________________________________________________________________________________________\n","activation_40 (Activation)      (None, 4, 4, 16)     0           batch_normalization_40[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_41 (Conv2D)              (None, 4, 4, 8)      1152        activation_40[0][0]              \n","__________________________________________________________________________________________________\n","dropout_40 (Dropout)            (None, 4, 4, 8)      0           conv2d_41[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_37 (Concatenate)    (None, 4, 4, 24)     0           concatenate_36[0][0]             \n","                                                                 dropout_40[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_41 (BatchNo (None, 4, 4, 24)     96          concatenate_37[0][0]             \n","__________________________________________________________________________________________________\n","activation_41 (Activation)      (None, 4, 4, 24)     0           batch_normalization_41[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_42 (Conv2D)              (None, 4, 4, 8)      1728        activation_41[0][0]              \n","__________________________________________________________________________________________________\n","dropout_41 (Dropout)            (None, 4, 4, 8)      0           conv2d_42[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_38 (Concatenate)    (None, 4, 4, 32)     0           concatenate_37[0][0]             \n","                                                                 dropout_41[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_42 (BatchNo (None, 4, 4, 32)     128         concatenate_38[0][0]             \n","__________________________________________________________________________________________________\n","activation_42 (Activation)      (None, 4, 4, 32)     0           batch_normalization_42[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_43 (Conv2D)              (None, 4, 4, 8)      2304        activation_42[0][0]              \n","__________________________________________________________________________________________________\n","dropout_42 (Dropout)            (None, 4, 4, 8)      0           conv2d_43[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_39 (Concatenate)    (None, 4, 4, 40)     0           concatenate_38[0][0]             \n","                                                                 dropout_42[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_43 (BatchNo (None, 4, 4, 40)     160         concatenate_39[0][0]             \n","__________________________________________________________________________________________________\n","activation_43 (Activation)      (None, 4, 4, 40)     0           batch_normalization_43[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_44 (Conv2D)              (None, 4, 4, 8)      2880        activation_43[0][0]              \n","__________________________________________________________________________________________________\n","dropout_43 (Dropout)            (None, 4, 4, 8)      0           conv2d_44[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_40 (Concatenate)    (None, 4, 4, 48)     0           concatenate_39[0][0]             \n","                                                                 dropout_43[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_44 (BatchNo (None, 4, 4, 48)     192         concatenate_40[0][0]             \n","__________________________________________________________________________________________________\n","activation_44 (Activation)      (None, 4, 4, 48)     0           batch_normalization_44[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_45 (Conv2D)              (None, 4, 4, 8)      3456        activation_44[0][0]              \n","__________________________________________________________________________________________________\n","dropout_44 (Dropout)            (None, 4, 4, 8)      0           conv2d_45[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_41 (Concatenate)    (None, 4, 4, 56)     0           concatenate_40[0][0]             \n","                                                                 dropout_44[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_45 (BatchNo (None, 4, 4, 56)     224         concatenate_41[0][0]             \n","__________________________________________________________________________________________________\n","activation_45 (Activation)      (None, 4, 4, 56)     0           batch_normalization_45[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_46 (Conv2D)              (None, 4, 4, 8)      4032        activation_45[0][0]              \n","__________________________________________________________________________________________________\n","dropout_45 (Dropout)            (None, 4, 4, 8)      0           conv2d_46[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_42 (Concatenate)    (None, 4, 4, 64)     0           concatenate_41[0][0]             \n","                                                                 dropout_45[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_46 (BatchNo (None, 4, 4, 64)     256         concatenate_42[0][0]             \n","__________________________________________________________________________________________________\n","activation_46 (Activation)      (None, 4, 4, 64)     0           batch_normalization_46[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_47 (Conv2D)              (None, 4, 4, 8)      4608        activation_46[0][0]              \n","__________________________________________________________________________________________________\n","dropout_46 (Dropout)            (None, 4, 4, 8)      0           conv2d_47[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_43 (Concatenate)    (None, 4, 4, 72)     0           concatenate_42[0][0]             \n","                                                                 dropout_46[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_47 (BatchNo (None, 4, 4, 72)     288         concatenate_43[0][0]             \n","__________________________________________________________________________________________________\n","activation_47 (Activation)      (None, 4, 4, 72)     0           batch_normalization_47[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_48 (Conv2D)              (None, 4, 4, 8)      5184        activation_47[0][0]              \n","__________________________________________________________________________________________________\n","dropout_47 (Dropout)            (None, 4, 4, 8)      0           conv2d_48[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_44 (Concatenate)    (None, 4, 4, 80)     0           concatenate_43[0][0]             \n","                                                                 dropout_47[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_48 (BatchNo (None, 4, 4, 80)     320         concatenate_44[0][0]             \n","__________________________________________________________________________________________________\n","activation_48 (Activation)      (None, 4, 4, 80)     0           batch_normalization_48[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_49 (Conv2D)              (None, 4, 4, 8)      5760        activation_48[0][0]              \n","__________________________________________________________________________________________________\n","dropout_48 (Dropout)            (None, 4, 4, 8)      0           conv2d_49[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_45 (Concatenate)    (None, 4, 4, 88)     0           concatenate_44[0][0]             \n","                                                                 dropout_48[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_49 (BatchNo (None, 4, 4, 88)     352         concatenate_45[0][0]             \n","__________________________________________________________________________________________________\n","activation_49 (Activation)      (None, 4, 4, 88)     0           batch_normalization_49[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_50 (Conv2D)              (None, 4, 4, 8)      6336        activation_49[0][0]              \n","__________________________________________________________________________________________________\n","dropout_49 (Dropout)            (None, 4, 4, 8)      0           conv2d_50[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_46 (Concatenate)    (None, 4, 4, 96)     0           concatenate_45[0][0]             \n","                                                                 dropout_49[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_50 (BatchNo (None, 4, 4, 96)     384         concatenate_46[0][0]             \n","__________________________________________________________________________________________________\n","activation_50 (Activation)      (None, 4, 4, 96)     0           batch_normalization_50[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_51 (Conv2D)              (None, 4, 4, 8)      6912        activation_50[0][0]              \n","__________________________________________________________________________________________________\n","dropout_50 (Dropout)            (None, 4, 4, 8)      0           conv2d_51[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_47 (Concatenate)    (None, 4, 4, 104)    0           concatenate_46[0][0]             \n","                                                                 dropout_50[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_51 (BatchNo (None, 4, 4, 104)    416         concatenate_47[0][0]             \n","__________________________________________________________________________________________________\n","activation_51 (Activation)      (None, 4, 4, 104)    0           batch_normalization_51[0][0]     \n","__________________________________________________________________________________________________\n","average_pooling2d_3 (AveragePoo (None, 2, 2, 104)    0           activation_51[0][0]              \n","__________________________________________________________________________________________________\n","flatten (Flatten)               (None, 416)          0           average_pooling2d_3[0][0]        \n","__________________________________________________________________________________________________\n","dense (Dense)                   (None, 10)           4170        flatten[0][0]                    \n","==================================================================================================\n","Total params: 240,086\n","Trainable params: 233,118\n","Non-trainable params: 6,968\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8Aqzk9AFXb1y","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626431666206,"user_tz":-330,"elapsed":5,"user":{"displayName":"Shivam Mittal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhjHp5yKJNkwNRhkEZO4wybVuTVd3nePN7rh-Rd3g=s64","userId":"17162462432229941707"}},"outputId":"d29eac2b-d7f6-4344-e42a-779b3e3ec870"},"source":["print(len(model.layers))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["262\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"b4XOsW3ahSkL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626442667072,"user_tz":-330,"elapsed":455,"user":{"displayName":"Shivam Mittal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhjHp5yKJNkwNRhkEZO4wybVuTVd3nePN7rh-Rd3g=s64","userId":"17162462432229941707"}},"outputId":"f2b5f1fd-db17-440d-9946-a7993e6ac6e7"},"source":["# determine Loss function and Optimizer\n","model.compile(loss='categorical_crossentropy',\n","              optimizer=SGD(lr=1e-1,decay=1e-6, momentum=0.9, nesterov=True),\n","              metrics=['accuracy'])"],"execution_count":33,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"vmsK0N2sYd96","executionInfo":{"status":"ok","timestamp":1626444279145,"user_tz":-330,"elapsed":504,"user":{"displayName":"Shivam Mittal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhjHp5yKJNkwNRhkEZO4wybVuTVd3nePN7rh-Rd3g=s64","userId":"17162462432229941707"}}},"source":["filepath=\"/content/sample_data/weights_densenetbc_6.best.hdf5\"\n","#callbacks\n","learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', \n","                                            patience=3, \n","                                            verbose=1, \n","                                            factor=0.5, \n","                                            min_lr=0.0001)\n","checkpoint_save = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n","\n","callbacks_list = [checkpoint_save,learning_rate_reduction]"],"execution_count":46,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KkqFbL02YmFh","executionInfo":{"status":"ok","timestamp":1626487709189,"user_tz":-330,"elapsed":41278,"user":{"displayName":"Shivam Mittal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhjHp5yKJNkwNRhkEZO4wybVuTVd3nePN7rh-Rd3g=s64","userId":"17162462432229941707"}},"outputId":"06c4dbb0-f359-49b5-c30b-3bb19cb4cedf"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Zyo-F28BArpe","executionInfo":{"status":"ok","timestamp":1626444285053,"user_tz":-330,"elapsed":1578,"user":{"displayName":"Shivam Mittal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhjHp5yKJNkwNRhkEZO4wybVuTVd3nePN7rh-Rd3g=s64","userId":"17162462432229941707"}}},"source":["\n","from keras.preprocessing import image\n","#data augmentation\n","datagen = image.ImageDataGenerator(\n","    zoom_range=0.3,\n","    rotation_range=15,\n","    horizontal_flip=True,\n","    fill_mode='nearest',\n","    \n","    )\n","datagen.fit(X_train)"],"execution_count":47,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DtLbB0glAyD5","outputId":"68a85916-bea2-42d0-e577-cabb197fe84d"},"source":["batch_size=60\n","epochs=80\n","#Fit the model on the batches generated by datagen.flow().\n","model.fit_generator(datagen.flow(X_train, y_train,\n","                                 batch_size=batch_size),\n","                        steps_per_epoch=len(X_train) / batch_size,\n","                        epochs=epochs,validation_data=(X_test, y_test),callbacks=callbacks_list)  "],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  warnings.warn('`Model.fit_generator` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/100\n","833/833 [==============================] - 175s 210ms/step - loss: 1.5529 - accuracy: 0.5887 - val_loss: 1.7967 - val_accuracy: 0.5629\n","\n","Epoch 00001: val_accuracy improved from -inf to 0.56290, saving model to /content/sample_data/weights_densenetbc_6.best.hdf5\n","Epoch 2/100\n","833/833 [==============================] - 182s 218ms/step - loss: 1.5031 - accuracy: 0.6044 - val_loss: 1.5011 - val_accuracy: 0.6236\n","\n","Epoch 00002: val_accuracy improved from 0.56290 to 0.62360, saving model to /content/sample_data/weights_densenetbc_6.best.hdf5\n","Epoch 3/100\n","833/833 [==============================] - 175s 210ms/step - loss: 1.4703 - accuracy: 0.6151 - val_loss: 1.5617 - val_accuracy: 0.6048\n","\n","Epoch 00003: val_accuracy did not improve from 0.62360\n","Epoch 4/100\n","833/833 [==============================] - 175s 210ms/step - loss: 1.4335 - accuracy: 0.6281 - val_loss: 1.5401 - val_accuracy: 0.6254\n","\n","Epoch 00004: val_accuracy improved from 0.62360 to 0.62540, saving model to /content/sample_data/weights_densenetbc_6.best.hdf5\n","Epoch 5/100\n","833/833 [==============================] - 175s 210ms/step - loss: 1.3998 - accuracy: 0.6341 - val_loss: 1.8629 - val_accuracy: 0.5391\n","\n","Epoch 00005: val_accuracy did not improve from 0.62540\n","Epoch 6/100\n","833/833 [==============================] - 175s 210ms/step - loss: 1.3747 - accuracy: 0.6442 - val_loss: 1.6046 - val_accuracy: 0.6125\n","\n","Epoch 00006: val_accuracy did not improve from 0.62540\n","Epoch 7/100\n","833/833 [==============================] - 175s 210ms/step - loss: 1.3495 - accuracy: 0.6531 - val_loss: 1.8129 - val_accuracy: 0.6035\n","\n","Epoch 00007: val_accuracy did not improve from 0.62540\n","\n","Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n","Epoch 8/100\n","833/833 [==============================] - 175s 210ms/step - loss: 1.2924 - accuracy: 0.6713 - val_loss: 1.4609 - val_accuracy: 0.6524\n","\n","Epoch 00008: val_accuracy improved from 0.62540 to 0.65240, saving model to /content/sample_data/weights_densenetbc_6.best.hdf5\n","Epoch 9/100\n","833/833 [==============================] - 183s 220ms/step - loss: 1.2788 - accuracy: 0.6755 - val_loss: 1.3993 - val_accuracy: 0.6615\n","\n","Epoch 00009: val_accuracy improved from 0.65240 to 0.66150, saving model to /content/sample_data/weights_densenetbc_6.best.hdf5\n","Epoch 10/100\n","833/833 [==============================] - 175s 210ms/step - loss: 1.2657 - accuracy: 0.6770 - val_loss: 1.4087 - val_accuracy: 0.6654\n","\n","Epoch 00010: val_accuracy improved from 0.66150 to 0.66540, saving model to /content/sample_data/weights_densenetbc_6.best.hdf5\n","Epoch 11/100\n","833/833 [==============================] - 175s 210ms/step - loss: 1.2533 - accuracy: 0.6820 - val_loss: 1.4766 - val_accuracy: 0.6509\n","\n","Epoch 00011: val_accuracy did not improve from 0.66540\n","Epoch 12/100\n","833/833 [==============================] - 175s 210ms/step - loss: 1.2416 - accuracy: 0.6853 - val_loss: 1.2772 - val_accuracy: 0.7018\n","\n","Epoch 00012: val_accuracy improved from 0.66540 to 0.70180, saving model to /content/sample_data/weights_densenetbc_6.best.hdf5\n","Epoch 13/100\n","833/833 [==============================] - 175s 210ms/step - loss: 1.2330 - accuracy: 0.6892 - val_loss: 1.3417 - val_accuracy: 0.6809\n","\n","Epoch 00013: val_accuracy did not improve from 0.70180\n","Epoch 14/100\n","833/833 [==============================] - 175s 210ms/step - loss: 1.2206 - accuracy: 0.6922 - val_loss: 1.3766 - val_accuracy: 0.6741\n","\n","Epoch 00014: val_accuracy did not improve from 0.70180\n","Epoch 15/100\n","833/833 [==============================] - 175s 210ms/step - loss: 1.2146 - accuracy: 0.6906 - val_loss: 1.4413 - val_accuracy: 0.6710\n","\n","Epoch 00015: val_accuracy did not improve from 0.70180\n","\n","Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n","Epoch 16/100\n","833/833 [==============================] - 175s 210ms/step - loss: 1.1821 - accuracy: 0.7034 - val_loss: 1.2820 - val_accuracy: 0.6973\n","\n","Epoch 00016: val_accuracy did not improve from 0.70180\n","Epoch 17/100\n","833/833 [==============================] - 175s 210ms/step - loss: 1.1776 - accuracy: 0.7074 - val_loss: 1.2351 - val_accuracy: 0.7092\n","\n","Epoch 00017: val_accuracy improved from 0.70180 to 0.70920, saving model to /content/sample_data/weights_densenetbc_6.best.hdf5\n","Epoch 18/100\n","833/833 [==============================] - 175s 210ms/step - loss: 1.1697 - accuracy: 0.7066 - val_loss: 1.3679 - val_accuracy: 0.6786\n","\n","Epoch 00018: val_accuracy did not improve from 0.70920\n","Epoch 19/100\n","833/833 [==============================] - 175s 210ms/step - loss: 1.1563 - accuracy: 0.7133 - val_loss: 1.2903 - val_accuracy: 0.6987\n","\n","Epoch 00019: val_accuracy did not improve from 0.70920\n","Epoch 20/100\n","833/833 [==============================] - 175s 210ms/step - loss: 1.1609 - accuracy: 0.7133 - val_loss: 1.4214 - val_accuracy: 0.6634\n","\n","Epoch 00020: val_accuracy did not improve from 0.70920\n","\n","Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n","Epoch 21/100\n","833/833 [==============================] - 175s 211ms/step - loss: 1.1372 - accuracy: 0.7184 - val_loss: 1.2468 - val_accuracy: 0.7125\n","\n","Epoch 00021: val_accuracy improved from 0.70920 to 0.71250, saving model to /content/sample_data/weights_densenetbc_6.best.hdf5\n","Epoch 22/100\n","833/833 [==============================] - 175s 211ms/step - loss: 1.1373 - accuracy: 0.7174 - val_loss: 1.3200 - val_accuracy: 0.6993\n","\n","Epoch 00022: val_accuracy did not improve from 0.71250\n","Epoch 23/100\n","833/833 [==============================] - 175s 210ms/step - loss: 1.1311 - accuracy: 0.7212 - val_loss: 1.2641 - val_accuracy: 0.7117\n","\n","Epoch 00023: val_accuracy did not improve from 0.71250\n","Epoch 24/100\n","833/833 [==============================] - 175s 211ms/step - loss: 1.1247 - accuracy: 0.7229 - val_loss: 1.2677 - val_accuracy: 0.7106\n","\n","Epoch 00024: val_accuracy did not improve from 0.71250\n","\n","Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n","Epoch 25/100\n","833/833 [==============================] - 175s 210ms/step - loss: 1.1142 - accuracy: 0.7262 - val_loss: 1.2398 - val_accuracy: 0.7144\n","\n","Epoch 00025: val_accuracy improved from 0.71250 to 0.71440, saving model to /content/sample_data/weights_densenetbc_6.best.hdf5\n","Epoch 26/100\n","833/833 [==============================] - 175s 210ms/step - loss: 1.1154 - accuracy: 0.7266 - val_loss: 1.2714 - val_accuracy: 0.7117\n","\n","Epoch 00026: val_accuracy did not improve from 0.71440\n","Epoch 27/100\n","833/833 [==============================] - 176s 211ms/step - loss: 1.1112 - accuracy: 0.7265 - val_loss: 1.2448 - val_accuracy: 0.7156\n","\n","Epoch 00027: val_accuracy improved from 0.71440 to 0.71560, saving model to /content/sample_data/weights_densenetbc_6.best.hdf5\n","Epoch 28/100\n","833/833 [==============================] - 176s 211ms/step - loss: 1.1108 - accuracy: 0.7289 - val_loss: 1.2322 - val_accuracy: 0.7180\n","\n","Epoch 00028: val_accuracy improved from 0.71560 to 0.71800, saving model to /content/sample_data/weights_densenetbc_6.best.hdf5\n","Epoch 29/100\n","833/833 [==============================] - 176s 211ms/step - loss: 1.1071 - accuracy: 0.7270 - val_loss: 1.2835 - val_accuracy: 0.7063\n","\n","Epoch 00029: val_accuracy did not improve from 0.71800\n","Epoch 30/100\n","833/833 [==============================] - 175s 210ms/step - loss: 1.1087 - accuracy: 0.7269 - val_loss: 1.2586 - val_accuracy: 0.7095\n","\n","Epoch 00030: val_accuracy did not improve from 0.71800\n","Epoch 31/100\n","833/833 [==============================] - 176s 211ms/step - loss: 1.1045 - accuracy: 0.7287 - val_loss: 1.2117 - val_accuracy: 0.7238\n","\n","Epoch 00031: val_accuracy improved from 0.71800 to 0.72380, saving model to /content/sample_data/weights_densenetbc_6.best.hdf5\n","Epoch 32/100\n","833/833 [==============================] - 175s 210ms/step - loss: 1.1052 - accuracy: 0.7272 - val_loss: 1.2251 - val_accuracy: 0.7194\n","\n","Epoch 00032: val_accuracy did not improve from 0.72380\n","Epoch 33/100\n","833/833 [==============================] - 176s 211ms/step - loss: 1.1034 - accuracy: 0.7306 - val_loss: 1.2159 - val_accuracy: 0.7193\n","\n","Epoch 00033: val_accuracy did not improve from 0.72380\n","Epoch 34/100\n","833/833 [==============================] - 176s 211ms/step - loss: 1.0994 - accuracy: 0.7299 - val_loss: 1.2740 - val_accuracy: 0.7158\n","\n","Epoch 00034: val_accuracy did not improve from 0.72380\n","\n","Epoch 00034: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n","Epoch 35/100\n","833/833 [==============================] - 176s 211ms/step - loss: 1.0957 - accuracy: 0.7319 - val_loss: 1.2068 - val_accuracy: 0.7246\n","\n","Epoch 00035: val_accuracy improved from 0.72380 to 0.72460, saving model to /content/sample_data/weights_densenetbc_6.best.hdf5\n","Epoch 36/100\n","833/833 [==============================] - 175s 210ms/step - loss: 1.0944 - accuracy: 0.7322 - val_loss: 1.2605 - val_accuracy: 0.7121\n","\n","Epoch 00036: val_accuracy did not improve from 0.72460\n","Epoch 37/100\n","833/833 [==============================] - 175s 210ms/step - loss: 1.0917 - accuracy: 0.7331 - val_loss: 1.2097 - val_accuracy: 0.7275\n","\n","Epoch 00037: val_accuracy improved from 0.72460 to 0.72750, saving model to /content/sample_data/weights_densenetbc_6.best.hdf5\n","Epoch 38/100\n","833/833 [==============================] - 175s 211ms/step - loss: 1.0915 - accuracy: 0.7336 - val_loss: 1.2124 - val_accuracy: 0.7213\n","\n","Epoch 00038: val_accuracy did not improve from 0.72750\n","Epoch 39/100\n","833/833 [==============================] - 176s 211ms/step - loss: 1.0934 - accuracy: 0.7351 - val_loss: 1.2142 - val_accuracy: 0.7239\n","\n","Epoch 00039: val_accuracy did not improve from 0.72750\n","Epoch 40/100\n","833/833 [==============================] - 175s 210ms/step - loss: 1.0902 - accuracy: 0.7338 - val_loss: 1.2093 - val_accuracy: 0.7243\n","\n","Epoch 00040: val_accuracy did not improve from 0.72750\n","\n","Epoch 00040: ReduceLROnPlateau reducing learning rate to 0.0001.\n","Epoch 41/100\n","833/833 [==============================] - 175s 210ms/step - loss: 1.0888 - accuracy: 0.7314 - val_loss: 1.2249 - val_accuracy: 0.7227\n","\n","Epoch 00041: val_accuracy did not improve from 0.72750\n","Epoch 42/100\n","833/833 [==============================] - 176s 211ms/step - loss: 1.0870 - accuracy: 0.7342 - val_loss: 1.2001 - val_accuracy: 0.7251\n","\n","Epoch 00042: val_accuracy did not improve from 0.72750\n","Epoch 43/100\n","833/833 [==============================] - 176s 211ms/step - loss: 1.0915 - accuracy: 0.7320 - val_loss: 1.1989 - val_accuracy: 0.7256\n","\n","Epoch 00043: val_accuracy did not improve from 0.72750\n","Epoch 44/100\n","833/833 [==============================] - 176s 211ms/step - loss: 1.0892 - accuracy: 0.7341 - val_loss: 1.1938 - val_accuracy: 0.7287\n","\n","Epoch 00044: val_accuracy improved from 0.72750 to 0.72870, saving model to /content/sample_data/weights_densenetbc_6.best.hdf5\n","Epoch 45/100\n","833/833 [==============================] - 176s 211ms/step - loss: 1.0915 - accuracy: 0.7332 - val_loss: 1.1773 - val_accuracy: 0.7309\n","\n","Epoch 00045: val_accuracy improved from 0.72870 to 0.73090, saving model to /content/sample_data/weights_densenetbc_6.best.hdf5\n","Epoch 46/100\n","833/833 [==============================] - 176s 211ms/step - loss: 1.0857 - accuracy: 0.7341 - val_loss: 1.1878 - val_accuracy: 0.7275\n","\n","Epoch 00046: val_accuracy did not improve from 0.73090\n","Epoch 47/100\n","833/833 [==============================] - 177s 212ms/step - loss: 1.0864 - accuracy: 0.7334 - val_loss: 1.2115 - val_accuracy: 0.7250\n","\n","Epoch 00047: val_accuracy did not improve from 0.73090\n","Epoch 48/100\n","833/833 [==============================] - 176s 212ms/step - loss: 1.0857 - accuracy: 0.7353 - val_loss: 1.2009 - val_accuracy: 0.7286\n","\n","Epoch 00048: val_accuracy did not improve from 0.73090\n","Epoch 49/100\n","833/833 [==============================] - 176s 211ms/step - loss: 1.0861 - accuracy: 0.7350 - val_loss: 1.2300 - val_accuracy: 0.7195\n","\n","Epoch 00049: val_accuracy did not improve from 0.73090\n","Epoch 50/100\n","833/833 [==============================] - 176s 211ms/step - loss: 1.0823 - accuracy: 0.7343 - val_loss: 1.1585 - val_accuracy: 0.7337\n","\n","Epoch 00050: val_accuracy improved from 0.73090 to 0.73370, saving model to /content/sample_data/weights_densenetbc_6.best.hdf5\n","Epoch 51/100\n","584/833 [====================>.........] - ETA: 49s - loss: 1.0823 - accuracy: 0.7353"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"crhGk7kEhXAz","scrolled":true},"source":["model.fit(X_train, y_train,\n","                    batch_size=batch_size,\n","                    epochs=epochs,\n","                    verbose=1, \n","                    validation_data=(X_test, y_test)) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZcWydmIVhZGr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626443364230,"user_tz":-330,"elapsed":21299,"user":{"displayName":"Shivam Mittal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhjHp5yKJNkwNRhkEZO4wybVuTVd3nePN7rh-Rd3g=s64","userId":"17162462432229941707"}},"outputId":"d01abe7b-bfe5-4360-d062-7d209ee28832"},"source":["# Test the model\n","score = model.evaluate(X_test, y_test, verbose=1)\n","print('Test loss:', score[0])\n","print('Test accuracy:', score[1])"],"execution_count":40,"outputs":[{"output_type":"stream","text":["313/313 [==============================] - 14s 45ms/step - loss: 1.6812 - accuracy: 0.5648\n","Test loss: 1.6811939477920532\n","Test accuracy: 0.5648000240325928\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UE3lF6EH1r_L"},"source":["# Save the trained weights in to .h5 format\n","model.save_weights(\"DNST_model.h5\")\n","print(\"Saved model to disk\")"],"execution_count":null,"outputs":[]}]}